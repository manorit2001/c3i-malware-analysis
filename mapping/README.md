# Mapping
This part maps and shows all the information processed by the analysis engine in a user friendly way which can be used to find anamolies in the system behavior

## Dependencies 
- [elasticsearch](https://www.elastic.co/guide/en/elasticsearch/reference/current/deb.html)
- [kibana](https://www.elastic.co/guide/en/kibana/current/deb.html)

## Configurations

### Elastic search
- Give `cluster.name` a relevant cluster name.
- Give a `node.name` a relevant node name.
- Configure the `network.host` as `0.0.0.0`
- Give `http.port` as 9200 which is default port.
- Configure the `discovery.type` as single-node.

### Kibana
- Give `server.name` a relevant server name.
- Uncomment elasticsearch `hosts`.
- Give a `port` to kibana we have configured to the default port `5601`.
- Configure the `server.host` to `0.0.0.0`

After all these things, start the `systemctl` services for `elasticsearch` and `kibana`


## Folders

### Configs
For getting a preconfigured dashboard, we have provided a an [Result_Dashboard.ndjson](configs/Result_Dashboard.ndjson) file for importing in kibana. 
You can refer to [this](https://www.progress.com/documentation/sitefinity-cms/load-custom-kibana-dashboards) for instructions on importing data in kibana

The other files are just for reference for importing just individual data instead of full dashboard

## Scripts
`mapping.py` is used to push data to kibana using elasticsearch api, You need to give the folder generated after `analysis` as it's argument. 
It'll find all the csv's generated in that folder and upload it to kibana. 
Agent handles this task automatically, you just have to setup the location of this script in it's `config.ini`

## Screenshots
It contains some screenshots of the dashboard with all the information being displayed in it
